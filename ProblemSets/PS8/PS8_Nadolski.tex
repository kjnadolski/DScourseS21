\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Problem Set 8}
\author{Karley Nadolski}
\date{March 31, 2021}

\begin{document}

\maketitle
\section{Comparing $\hat{\beta}_{OLS}$ to $\beta$ values}
\begin{table} [h]
\centering
\begin{tabular}[t]{lcc}
  & $\hat{\beta}_{OLS}$ using lm() & True $\beta$ values\\
X1 & 1.493 & 1.5\\
 & (0.005)\\
X2 & -1.014 & -1\\
 & \vphantom{8} (0.010)\\
X3 & -0.238 & -0.25\\
 & \vphantom{7} (0.010)\\
X4 & 0.728 & 0.75\\
 & \vphantom{6} (0.010)\\
X5 & 3.493 & 3.5\\
 & \vphantom{5} (0.010)\\
X6 & -1.993 & -2\\
 & \vphantom{4} (0.010)\\
X7 & 0.483 & 0.5\\
 & \vphantom{3} (0.010)\\
X8 & 0.996 & 1\\
 & \vphantom{2} (0.010)\\
X9 & 1.252 & 1.25\\
 & \vphantom{1} (0.010)\\
X10 & 1.980 & 2\\
 & (0.010)\\
Num.Obs. & 10000\\
R2 & 0.971\\
R2 Adj. & 0.971\\
AIC & 14359.7\\
BIC & 14439.0\\
Log.Lik. & -7168.850\\
F & 33160.246\\
\end{tabular}
\end{table}

The $\hat{\beta}_{OLS}$ estimates from using the lm() function are definitely similar to the true $\beta$ values, but aren't as precise as estimates from other optimization methods (like gradient descent, L-BFGS, or the Nelder-Mead algorithm). That being said, most of the estimates (besides X4) are within two standard errors of the true beta value. Even for the estimate for X4, the true value of $/beta$ is 0.75 and the $\hat{\beta}_{OLS}$ estimate is 0.728. With a standard error of 0.010, the true value lies just 0.02 beyond the estimate with the addition of two standard errors. 

\end{document}
